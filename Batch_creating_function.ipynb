{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# This function depends on a vocabulary as created by \n",
    "#def create_integer_vocabulary(word_freqs, max_voc_size):\n",
    "#    \"\"\" \n",
    "#    Create vocabulary where common words are matched to integers. \n",
    "#    \"\"\"\n",
    "#    \n",
    "#    word_list = []\n",
    "#\n",
    "#    if len(word_freqs.most_common()) > max_voc_size:\n",
    "#        vocab = word_freqs.most_common()[0:max_voc_size]\n",
    "#\n",
    "#    else:\n",
    "#        vocab = word_freqs\n",
    "#\n",
    "#    for i in range(len(vocab)):\n",
    "#        word_list.append(vocab[i][0])\n",
    "#\n",
    "#    # Get pairs of elements    \n",
    "#    tmp = zip(word_list, range(1,max_voc_size+1))\n",
    "#    # Make pairs into a dictionary\n",
    "#    vocab = dict(tmp)\n",
    "#\n",
    "#    # Create default dictionary - returns 0 if an undefined key is called\n",
    "#    vocab2 = defaultdict(int)\n",
    "#    vocab2.update(vocab)\n",
    "#\n",
    "#    # Double check that it returns 0\n",
    "#    # print(vocab2[\"terehgdjhshrersg\"])\n",
    "#    \n",
    "#    return vocab2\n",
    "\n",
    "def create_batches(batch_size,vocabulary,filename,ENCODING):\n",
    "    counter=0 # will end up being the number of lines in the document\n",
    "    len_lines = [] # will contain maximum length of a line in each batch\n",
    "    tmp_lines = []\n",
    "    \n",
    "    with open(filename, encoding=ENCODING) as f:\n",
    "        for line in f:\n",
    "            counter+=1\n",
    "            tokens = line.lower().split()\n",
    "            tmp_lines.append(len(tokens))\n",
    "\n",
    "            if (counter % batch_size == 0):\n",
    "                len_lines.append(max(tmp_lines))\n",
    "                tmp_lines = []\n",
    "        #This takes care of the last batch if number of lines is not an exact multiple of batch_size\n",
    "        if (counter % batch_size != 0): \n",
    "            len_lines.append(max(tmp_lines)) # if at end of the file\n",
    "    \n",
    "    with open(filename, encoding=ENCODING) as f:\n",
    "        batches=[]\n",
    "        batch_counter=0\n",
    "        line_counter=0\n",
    "\n",
    "        for line in f:\n",
    "            #This creates a temporary array each time we start a new batch\n",
    "            if line_counter % batch_size == 0:\n",
    "                tmp_array=np.zeros(shape=(batch_size,len_lines[batch_counter])) #fill this temporary array\n",
    "\n",
    "\n",
    "            tokens = line.lower().split()\n",
    "            line_as_int = list(map(vocabulary.get, tokens))\n",
    "            line_as_int = [-1 if x is None else x for x in line_as_int] # set None values to -1\n",
    "\n",
    "\n",
    "            tmp_array[line_counter % batch_size,0:(len(line_as_int))]=line_as_int\n",
    "\n",
    "            line_counter+=1 #when we done\n",
    "            if line_counter % batch_size ==0:\n",
    "                batches.append(tmp_array)\n",
    "                batch_counter+=1\n",
    "\n",
    "        # again this takes care of the final batch if number of lines is not multiple of batch_size\n",
    "        if line_counter % batch_size != 0:\n",
    "            tmp_array=tmp_array[0:(line_counter % batch_size),:]\n",
    "            batches.append(tmp_array)\n",
    "        \n",
    "    return (counter,batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's an example run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_voc_size = 1000\n",
    "book_freqs = count_word_frequencies(\"a1_data/books.txt\", 'ISO-8859-1')\n",
    "vocab_books = create_integer_vocabulary(book_freqs, max_voc_size)\n",
    "num_lines,batches=create_batches(batch_size=101,vocabulary=vocab_books,filename='a1_data/books.txt',ENCODING='ISO-8859-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
