{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing word embeddings for improving OCR accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will work on this project with Adnan Fazlinovic. \n",
    "\n",
    "Our idea is to compare how different embeddings affect OCR accuracy, similar to the approach taken in this article: https://medium.com/states-title/using-nlp-bert-to-improve-ocr-accuracy-385c98ae174c (Links to an external site.)\n",
    "\n",
    "We would like to try some embeddings we have learned about in the course, such as CBoW, word2vec, FastText, ELMo, BERT. If we have more time and find other interesting representations online we will evaluate them as well. The idea is to find a baseline OCR accuracy and then exploring if, and how much, this accuracy can be improved by applying word embeddings to the incorrectly scanned words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Probably use a synthetic dataset (read in europarl corpus and corrupt it a bit)\n",
    "- Richard suggests corrupting it in ways that often happen in OCR, like rn <-> m, i <-> l, cl <-> d \n",
    "    - (https://scribenet.com/articles/2016/03/04/how-to-get-the-most-out-of-ocr)\n",
    "- I think he means we should use a spellchecker to find misspelled words, and check with NER that they are not a name\n",
    "- Then maybe we don't throw out the misspelled word, it can be useful\n",
    "\n",
    "It feels like we're mostly making a spell/grammar checking model - that's fine\n",
    "\n",
    "- Richard thinks that character level embeddings can be useful here\n",
    "- Evaluation of performance: see what people usually use within OCR. Some ideas:\n",
    "\n",
    "    - https://www.aclweb.org/anthology/I17-1101.pdf\n",
    "    - https://loicbarrault.github.io/papers/afli_cicling2015.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from enchant.checker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(\"en-UK\")\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Try out spellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell.check(\"cat's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spiel',\n",
       " 'spelt',\n",
       " 'spell',\n",
       " 'seel',\n",
       " 'spec',\n",
       " 'sped',\n",
       " 'spew',\n",
       " 'Opel',\n",
       " 'sp el',\n",
       " 'sp-el']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell.suggest(\"spel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and corrupt the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character elision is when letter pairs and individual letters are confused by the software. These types of errors occur any time pairs of letters are shaped similarly to other letters. Six common pairs are:\n",
    "\n",
    "rn <-> m, cl <-> d, vv <-> w, ol <-> d, li <-> h, nn <-> m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "elisionArray = []\n",
    "elisionArray.append(['rn', 'm'])\n",
    "elisionArray.append(['ol', 'd'])\n",
    "elisionArray.append(['cl', 'd'])\n",
    "elisionArray.append(['vv', 'w'])\n",
    "elisionArray.append(['li', 'h'])\n",
    "elisionArray.append(['nn', 'm'])\n",
    "elisionArray = np.array(elisionArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## An example of how the character elision will be handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I smilingly scorn this little barn with my lilac yarn and delicious fern\n",
      "--> Replaced  rn  at position  15 \n",
      "I smilingly scom this little barn with my lilac yarn and delicious fern\n",
      "--> Replaced  rn  at position  32 \n",
      "I smilingly scom this little bam with my lilac yarn and delicious fern\n",
      "--> Replaced  rn  at position  51 \n",
      "I smilingly scom this little bam with my lilac yam and delicious fern\n",
      "--> Replaced  rn  at position  70 \n",
      "I smilingly scom this little bam with my lilac yam and delicious fem\n",
      "--> Replaced  li  at position  5 \n",
      "I smihngly scom this little bam with my lilac yam and delicious fem\n",
      "--------------------------------------------------------------------------------\n",
      "Total errors:  5\n",
      "[(0, [(1, 'smilingly'), (2, 'scorn'), (5, 'barn'), (9, 'yarn'), (12, 'fern')])]\n"
     ]
    }
   ],
   "source": [
    "# A test sentence that contains a lot of 'rn' and 'li'\n",
    "line = \"I smilingly scorn this little barn with my lilac yarn and delicious fern\"\n",
    "print(line)\n",
    "\n",
    "new_line = line\n",
    "elision_prob = 0.5\n",
    "\n",
    "# Randomize search order, since some letter pairs overlap \n",
    "elisionArray = np.random.permutation(elisionArray)\n",
    "for pair in elisionArray:\n",
    "    \n",
    "    n_errors = 0\n",
    "    \n",
    "    for m in re.finditer(pair[0], new_line):\n",
    "        \n",
    "        rd = np.random.rand(1)\n",
    "        if rd < elision_prob:\n",
    "            \n",
    "            # Note that the position can't be used later since the line changes length!\n",
    "            print(\"--> Replaced \", pair[0], \" at position \", m.start(), \"\")\n",
    "            \n",
    "            tmp = list(new_line)\n",
    "            tmp[m.start()-n_errors:m.end()-n_errors] = \"%%\"\n",
    "            new_line = \"\".join(tmp)\n",
    "            new_line = new_line.replace(\"%%\", pair[1])\n",
    "            \n",
    "            print(new_line)\n",
    "\n",
    "            # count number of replacements\n",
    "            n_errors += 1\n",
    "            \n",
    "print('-'*80)\n",
    "\n",
    "# Save location and correct spelling for the corrupted words\n",
    "\n",
    "line = list(line.split())\n",
    "new_line = list(new_line.split())\n",
    "\n",
    "total_errors = 0\n",
    "ground_truth = []\n",
    "\n",
    "# This will be the index of a document in the corpus\n",
    "doc_num = 0     \n",
    "\n",
    "# This contains the ground truth for each document \n",
    "tmp = []\n",
    "\n",
    "for j in range(len(line)):\n",
    "    if line[j] != new_line[j]:\n",
    "        \n",
    "        total_errors += 1\n",
    "        tmp.append((j, line[j]))\n",
    "        \n",
    "ground_truth.append((doc_num, tmp))\n",
    "print(\"Total errors: \", total_errors)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply character elision to the Europarl data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_line_errors(line, new_line, total_errors):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check for errors between gold standard document and \"OCR\" document.\n",
    "    \"\"\"\n",
    "\n",
    "    line = list(line.split())\n",
    "    new_line = list(new_line.split()) \n",
    "    truth = []\n",
    "\n",
    "    for j in range(len(line)):\n",
    "        if line[j] != new_line[j]:\n",
    "\n",
    "            total_errors += 1\n",
    "            truth.append((j, line[j]))\n",
    "    \n",
    "    return truth, total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_data(corpus_file, corpus_encoding, max_lines, elisionArray, elision_prob):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in ground truth version of the text, and a (synthetic) corrupted OCR dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_errors = 0\n",
    "    ground_truth = []\n",
    "    doc_errors = []\n",
    "    corrupted_data = []\n",
    "    \n",
    "    with open(corpus_file, encoding = corpus_encoding) as f:\n",
    "        \n",
    "        for d, line in enumerate(f):\n",
    "        \n",
    "            if d == max_lines:\n",
    "                break\n",
    "        \n",
    "            ground_truth.append(line) \n",
    "            new_line = line\n",
    "            \n",
    "            # Randomize search order, since some letter pairs overlap \n",
    "            elisionArray = np.random.permutation(elisionArray)\n",
    "            for pair in elisionArray:\n",
    "                \n",
    "                # Count number of times each letter pair has been corrupted (since this changes the line length)\n",
    "                n_errors = 0 \n",
    "                \n",
    "                for m in re.finditer(pair[0], new_line):\n",
    "                    \n",
    "                    rd = np.random.rand(1)\n",
    "                    if rd < elision_prob:\n",
    "                        \n",
    "                        # Replace the letter pair and convert to a new line\n",
    "                        tmp = list(new_line)\n",
    "                        tmp[m.start()-n_errors:m.end()-n_errors] = \"%%\"\n",
    "                        new_line = \"\".join(tmp)\n",
    "                        new_line = new_line.replace(\"%%\", pair[1])\n",
    "\n",
    "                        # count number of replacements\n",
    "                        n_errors += 1\n",
    "                     \n",
    "            corrupted_data.append(new_line)\n",
    "            line_truth, total_errors = check_line_errors(line, new_line, total_errors)\n",
    "            if len(line_truth) > 0:\n",
    "                doc_errors.append((d, line_truth))\n",
    "            \n",
    "    return ground_truth, corrupted_data, doc_errors, total_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def identify_spelling_errors(data, ignore):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a dataset and a list of characters to ignore, find misspelled words that are _not_ names.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_misspelled = 0\n",
    "\n",
    "    for line in data:\n",
    "\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "\n",
    "            if not word in ignore and not spell.check(word):\n",
    "\n",
    "                # Apply nlp pipeline, check if this \"misspelled word\" is a name\n",
    "                result = nlp(line, disable = ['tagger', 'parser'])\n",
    "                is_name = False\n",
    "\n",
    "                for entity in result.ents:\n",
    "                    if entity.label_ in  [\"PERSON\", \"NORP\", \"GPE\", \"ORG\"] and entity.text.find(word) > -1:\n",
    "                        is_name = True\n",
    "\n",
    "                if not is_name:\n",
    "\n",
    "                    # note down the line, word and location - this is what we will try to correct!\n",
    "                    print(word)\n",
    "\n",
    "                    n_misspelled += 1\n",
    "\n",
    "    return n_misspelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\saran\\OneDrive\\Dokument\\GitHub\\NLP\\Project5\\europarl.txt\"\n",
    "encoding = \"utf-8\"\n",
    "\n",
    "# Probability that a letter pair from our list will be confused if it is seen in the text\n",
    "elision_prob = 0.1\n",
    "max_lines = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "ground_truth, data, doc_errors, n_errors = read_data(file, encoding, max_lines, elisionArray, elision_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "famihes\n",
      "selfemployed\n",
      "apphcation\n",
      "renationalise\n",
      "ultra-hberal\n",
      "pohcy\n",
      "160_000\n",
      "black-marketeering\n",
      "concems\n",
      "hke\n",
      "Sdbes\n",
      "trialogue\n"
     ]
    }
   ],
   "source": [
    "# Words and characters for the spellchecker to ignore\n",
    "ignore = [\",\", \".\", '\"', \"(\", \")\", \"-\", \"'\", \"!\", \"?\", \":\", \";\", \"/\", \"n't\", \"'s\", \"'m\", \"%\", \"--\", \"___LANGCODE___\"]\n",
    "n_misspelled = identify_spelling_errors(data, ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identified misspelled words:  12\n",
      "Number of synthetic errors:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of identified misspelled words: \", n_misspelled)\n",
    "print(\"Number of synthetic errors: \", total_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two approaches: either throw away the misspelled word and try to fill it in from context, or use character level embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute baseline accuracy using spellcheck suggestions\n",
    "\n",
    "baseline: use top suggested word from enchant spellchecker\n",
    "\n",
    "\n",
    "so I guess we create a list of misspelled words just like doc_errors, apply the suggestion for each, and see if we get closer to the ground truth or not? Will have to read his articles to make sure how to evaluate the performance\n",
    "\n",
    "- https://www.aclweb.org/anthology/I17-1101.pdf\n",
    "- https://loicbarrault.github.io/papers/afli_cicling2015.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to fill in missing words using BERT \n",
    "(like in the article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some other word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try some character level embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
